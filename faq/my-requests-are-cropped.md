---
icon: circle-question
---

# My requests are cropped?

#### Max tokens

AI/ML API has a parameter called `max_tokens`. Usually, this parameter can be crucial if your requests are large and can lead to text cropping. This parameter controls the maximum number of input and output tokens combined that your model will use inside your request and can save your tokens if the generation is larger than you expect. Try to adjust it and see the result.

You can read more about `max_tokens` and other parameters [here](../api-overview/text-models-llm/parameters.md).
